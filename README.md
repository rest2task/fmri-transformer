# R2Tâ€‘Net

**R2Tâ€‘Net** is a PyTorchâ€‘Lightning framework for learning a *single* 2â€¯048â€‘dimensional â€œbrainâ€‘signatureâ€ vector from both restingâ€‘state (rsâ€‘fMRI) and task (tâ€‘fMRI) data.  
A Transformer encoder (Stepâ€¯1) turns each 4â€‘D volume or ROIâ€‘timeseries into that signature; a contrastive NTâ€‘Xent loss (Stepâ€¯2) makes signatures from the *same* person / different modalities attract, while pushing *different* people apart.

---

## ğŸŒâ€¯Motivation

Most pipelines treat rsâ€‘fMRI and tâ€‘fMRI separatelyâ€”often collapsing tâ€‘fMRI into static contrast maps. That discards temporal information and limits subjectâ€‘specific modelling.  
**R2Tâ€‘Net** jointly embeds both modalities so the signature is:

* **Modalityâ€‘invariant**â€ƒ(restâ€¯â‡„â€¯task)  
* **Personâ€‘specific**â€ƒ(positive pairs = same subject)  
* **Timeâ€‘stable**â€ƒ(good testâ€“retest reliability)  
* **Predictive**â€ƒfor cognition / behaviour from rsâ€‘fMRI alone  

---

## ğŸ§±â€¯Backbone Flexibility

Any encoder that outputs a `[B,â€¯embed_dim]` feature can plug in by editing  
`module/models/load_model.py`.

| Category           | Examples you can register |
|--------------------|---------------------------|
| **Transformerâ€‘4D** | `swin4d_ver7`Â (default), `vit`, `transformer2d`, TimeSformerâ€‘style |
| **3â€‘D CNN**        | `resnet3d`, `densenet3d`, `r3d_18`, `unet3d` |
| **Hybrid**         | CNNâ€¯+â€¯GRU, Perceiver IO, Temporalâ€‘Uâ€‘Net |

(The repo ships with Swinâ€‘4D and a fallback to any ViT fromÂ `timm`.)

---

## ğŸ”§â€¯Key Features

| Feature | Details |
|---------|---------|
| **Flexible input** | Raw 4â€‘D volumesÂ `[C,H,W,D,T]`, grayordinatesÂ `[91â€¯282,T]`, or parcellated ROIÂ `[V,T]` |
| **Transformer or CNN** | Swap backbone via `--model`. External 3â€‘D patchâ€‘embedding provided for ViTâ€‘style nets. |
| **Contrastive + Supervised** | Add `--contrastive` for NTâ€‘Xent; downstream regression / classification head is always present. |
| **Cosineâ€‘Warmup scheduler** | `--use_scheduler` activates `CosineAnnealingWarmUpRestarts`. |
| **Metrics** | Pearson /Â MSE /Â MAE for regression, Balancedâ€‘Acc /Â AUROC for classification (Lightningâ€™s `torchmetrics`). |

---

## ğŸ“â€¯Directory Layout

```

R2TNet/
â”œâ”€â”€ train.py            # training / validation / test
â”œâ”€â”€ inference.py        # batch inference on rsâ€‘fMRI
â”‚
â”œâ”€â”€ module/
â”‚   â”œâ”€â”€ r2tnet.py       # LightningModule (encoder + heads + loss)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ load\_model.py
â”‚   â”‚   â”œâ”€â”€ swin4d\_transformer\_ver7.py
â”‚   â”‚   â””â”€â”€ swin\_transformer.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data\_module.py
â”‚       â”œâ”€â”€ datasets.py
â”‚       â”œâ”€â”€ patch\_embedding.py
â”‚       â””â”€â”€ lr\_scheduler.py
â”‚
â””â”€â”€ logs/               # created automatically (checkpoints + TensorBoard)

````

---

## ğŸš€â€¯Quick Start

### 1â€¯Â·â€¯Install

```bash
pip install pytorch-lightning torch timm einops torchmetrics scikit-learn
````

### 2â€¯Â·â€¯Prepare data

```
data/S1200/
â””â”€â”€ img/100307/frame_0.pt  frame_1.pt ...
```

Each `frame_*.pt` is a tensor `[C,H,W,D]` for one TR.

### 3â€¯Â·â€¯Supervised training

```bash
python train.py \
  --data_dir data/S1200 \
  --dataset_type rest \
  --batch_size 4 \
  --model swin4d_ver7 \
  --max_epochs 50
```

### 4â€¯Â·â€¯Contrastive preâ€‘training

```bash
python train.py \
  --data_dir data/S1200 \
  --dataset_type rest \
  --contrastive --use_scheduler \
  --model swin4d_ver7
```

### 5â€¯Â·â€¯Inference (rsâ€‘fMRI â†’ cognitive score)

```bash
python inference.py \
  --ckpt logs/epoch03-valid_loss=0.2100.ckpt \
  --input_dir data/S1200/img/ \
  --output rs_predictions.csv
```

---

## ğŸ§ â€¯Applications

* Predict fluid intelligence, memory, personality from rsâ€‘fMRI
* Replace long multiâ€‘task scans with one short resting scan
* Transferâ€‘learning to clinical cohorts (e.g., ADNI, ABCD)

---

## ğŸ“œâ€¯License

Released under the MIT License â€“ free for research and commercial use.
