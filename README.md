# R2T‚ÄëNet

**R2T‚ÄëNet** is a PyTorch‚ÄëLightning framework that turns any 4‚ÄëD fMRI sample‚Äîresting‚Äëstate (rs‚ÄëfMRI) or task (t‚ÄëfMRI)‚Äîinto a single **1024‚Äëdimensional brain‚Äësignature**.  
A Transformer encoder (Step‚ÄØ1) creates the signature; an NT‚ÄëXent contrastive loss (Step‚ÄØ2) makes signatures from the *same* subject and *different* modalities attract, while pushing signatures from *different* subjects apart.  
A small supervised head can then predict cognition or behaviour from the signature.

---

## üåê‚ÄØMotivation

Traditional pipelines handle rs‚ÄëfMRI and t‚ÄëfMRI separately, often compressing t‚ÄëfMRI into static contrast maps‚Äîlosing temporal dynamics and personalization.  
**R2T‚ÄëNet** instead:

* Learns a **modality‚Äëinvariant** embedding (rest¬†‚áÑ¬†task).  
* Produces **person‚Äëspecific** vectors (positive pairs = same subject).  
* Shows good **test‚Äìretest stability**.  
* Lets you predict behaviour from *resting scans only*, cutting scan time.

---

## üß±‚ÄØBackbone Flexibility

Edit one line in `module/models/load_model.py` to plug in any encoder that outputs a `[B,‚ÄØembed_dim]` feature:

| Category           | Examples |
|--------------------|----------|
| Transformer‚Äë4D     | `swin4d_ver7`¬†(default)¬†¬∑  ViT¬†¬∑¬†TimeSformer |
| 3‚ÄëD CNN            | 3‚ÄëD‚ÄØResNet, 3‚ÄëD‚ÄØDenseNet, UNet‚Äë3D |
| Hybrid             | CNN‚ÄØ+‚ÄØGRU, Perceiver IO, Temporal‚ÄëU‚ÄëNet |

---

## üîß‚ÄØKey Features

| Feature | Details |
|---------|---------|
| **Input‚Äëagnostic** | Raw 4‚ÄëD volumes `[C,H,W,D,T]`, grayordinates `[91‚ÄØ282,T]`, or ROI series `[V,T]` |
| **Always contrastive** | NT‚ÄëXent runs in every mode; you choose to freeze or unfreeze the prediction head |
| **Cosine‚Äëwarmup scheduler** | Enable with `--use_scheduler` |
| **Metrics out‚Äëof‚Äëthe‚Äëbox** | Pearson‚ÄØ/‚ÄØMSE‚ÄØ/‚ÄØMAE (regression), Balanced‚ÄëAcc‚ÄØ/‚ÄØAUROC (classification) |
| **Runs on a single GPU** | Batch accumulation + mixed precision available |

---

## üìÅ‚ÄØDirectory Layout

```

R2TNet/
‚îú‚îÄ‚îÄ train.py                # train / validate / test
‚îú‚îÄ‚îÄ inference.py            # batch inference on rs‚ÄëfMRI
‚îÇ
‚îú‚îÄ‚îÄ module/
‚îÇ   ‚îú‚îÄ‚îÄ r2tnet.py           # LightningModule (encoder + heads + losses)
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ load_model.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ swin4d_transformer_ver7.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ swin_transformer.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ data_module.py
‚îÇ       ‚îú‚îÄ‚îÄ datasets.py
‚îÇ       ‚îú‚îÄ‚îÄ patch_embedding.py
‚îÇ       ‚îî‚îÄ‚îÄ lr_scheduler.py
‚îÇ
‚îî‚îÄ‚îÄ logs/                   # auto‚Äëgenerated (TensorBoard & checkpoints)

````

---


## üöÄ‚ÄØQuick Start

Train and evaluate on 4D fMRI, ROI series, or grayordinates ‚Äî all from one CLI.


### 1 ¬∑ Install

```bash
# PyTorch 2.x with CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Core dependencies
pip install pytorch-lightning timm einops torchmetrics scikit-learn

# Optional extras
pip install monai pandas matplotlib
```


### 2 ¬∑ Prepare your data

```
data/S1200/
‚îú‚îÄ‚îÄ img/
‚îÇ   ‚îú‚îÄ‚îÄ 100307/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frame_0.pt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frame_1.pt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ 103414/
‚îî‚îÄ‚îÄ meta/
    ‚îú‚îÄ‚îÄ subject_dict.json        # {"100307": [0, 83.2], ...}
    ‚îî‚îÄ‚îÄ splits.json              # {"train": [...], "val": [...], "test": [...]}
```

* Each `frame_*.pt` is a tensor shaped `[C, H, W, D]` (for 4D fMRI).
* ROIs or grayordinates should be saved as `[V]` tensors per frame.
* Optional: `voxel_mean.pt` and `voxel_std.pt` for normalization.


### 3 ¬∑ Training Paradigms

| Mode                | NT-Xent | Supervised | CLI Flags                                                |
| ------------------- | ------- | ---------- | -------------------------------------------------------- |
| **Self-supervised** | ‚úÖ       | ‚ùå (frozen) | `--contrastive --pretraining --freeze_head`              |
| **Full fine-tune**  | ‚úÖ       | ‚úÖ          | `--contrastive` *(default)*                              |
| **Linear probe**    | ‚ùå       | ‚úÖ (frozen) | `--freeze_encoder --downstream_task_type classification` |

> ‚ö†Ô∏è Omitting `--contrastive` disables NT-Xent loss (core to R2T‚ÄëNet).


### 4 ¬∑ Example Commands

#### A. Self-supervised Pre-training

```bash
python train.py \
  --data_dir data/S1200 \
  --dataset_type rest \
  --contrastive --pretraining --freeze_head \
  --model swin4d_ver7 \
  --batch_size 8 --max_epochs 50 \
  --use_scheduler --total_steps 20000
```

#### B. Fine-tune with Labels (Regression)

```bash
python train.py \
  --data_dir data/S1200 \
  --dataset_type rest \
  --contrastive \
  --load_model logs/last.ckpt \
  --downstream_task_type regression \
  --label_scaling_method standardization \
  --model swin4d_ver7 \
  --batch_size 4 --max_epochs 30 --use_scheduler
```

#### C. Evaluate/Test Only

```bash
python train.py \
  --test_only --test_ckpt logs/epoch02-valid_loss=0.2100.ckpt \
  --data_dir data/S1200
```


### 5 ¬∑ Inference (e.g., rs-fMRI ‚Üí prediction)

```bash
python inference.py \
  --ckpt logs/epoch03-valid_loss=0.2100.ckpt \
  --input_dir data/S1200/img \
  --input_kind vol \
  --output rs_predictions.csv
```

Output: CSV file with columns `subject_id,prediction`.


### 6 ¬∑ Recommended Flags

| Flag                              | Purpose                                        |
| --------------------------------- | ---------------------------------------------- |
| `--precision 16`                  | Mixed precision ‚Äî saves memory                 |
| `--accumulate_grad_batches 2`     | Gradient accumulation (for small GPUs)         |
| `--resume_from_checkpoint ...`    | Resume training from last/best                 |
| `--balanced_sampling`             | Ensures equal subject exposure per epoch       |
| `--num_rois 360 --input_kind roi` | Switch to ROI-based input (instead of volumes) |
| `--grayordinates`                 | Use 91,282-dim grayordinate inputs             |


### 7 ¬∑ Troubleshooting

| Symptom             | Likely Fix                                     |
| ------------------- | ---------------------------------------------- |
| **CUDA OOM**        | Reduce `--batch_size`, or add `--precision 16` |
| **Loss = NaN**      | Check `--total_steps` ‚â´ `--warmup_pct`         |
| **AUROC = 0.5**     | Check for constant or missing labels           |
| **Slow dataloader** | Increase `--num_workers`; pre-convert to `.pt` |


### 8 ¬∑ Next Steps

* ‚úÖ Try other encoders: `--model resnet3d18`, `vit`, `cnn_gru`, `temporal_unet`
* ‚úÖ Multi-GPU: `--accelerator gpu --devices 8 --strategy ddp`
* ‚úÖ Export to ONNX: `python export_onnx.py --ckpt logs/last.ckpt`

---

## üß†‚ÄØApplications

* Predict fluid intelligence, memory, personality from *resting scans only*
* Shorten scan protocols in population studies
* Transfer‚Äëlearn to clinical cohorts (ADNI, ABCD, UK Biobank)
